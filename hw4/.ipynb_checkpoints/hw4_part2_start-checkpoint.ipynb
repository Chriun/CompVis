{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9536d9ad-250a-4323-9c4b-90c1137c59b3",
   "metadata": {},
   "source": [
    "### HW 4, Part 2, Start\n",
    "### CSCI 4270 and 6270, Spring 2024\n",
    "\n",
    "This is starter code for HW 4, Part 2. Most important is the definition of the Dataset object for loading, separately, the train, validation and test image sets. Students can use as much or as little of this as they wish and can modify it in anyway they'd like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bece3632-019b-4ac0-be8c-39e882243355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c77e33-318a-4997-a3ae-9ed9dbbe98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image(fn):\n",
    "    extensions = ['.jpg', '.jpeg', '.png']\n",
    "    return any(fn.lower().endswith(ext) for ext in extensions)\n",
    "\n",
    "def find_images_in_folder(folder_path, verbose=False):\n",
    "    full_image_paths = []\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Check if the file is an image\n",
    "        if os.path.isfile(file_path) and is_image(filename):\n",
    "            # Try opening the image\n",
    "            try:\n",
    "                im = Image.open(file_path)\n",
    "                full_image_paths.append(file_path)\n",
    "                if verbose:\n",
    "                    print(f\"Read image: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error failed to read {filename}: {e}\")\n",
    "#     print(f'Returing {len(full_image_paths)} image paths')\n",
    "    return full_image_paths\n",
    "\n",
    "folder_path = \"hw4_data/valid/ocean\"\n",
    "full_paths = find_images_in_folder(folder_path, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213dff20-1862-4140-b684-893fe5b2e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Provide a Dataset object for the five class dataset.\n",
    "'''\n",
    "\n",
    "# These are empirically determined values to optimize image intensity rescaling prior to training\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "'''\n",
    "The Dataset class we write must include the __init__, __len__ and __getitem__ (subscripting) \n",
    "methods.\n",
    "'''\n",
    "class HW4_Dataset(Dataset):\n",
    "    def __init__(self, path, class_names, new_size=None, verbose=False):\n",
    "        '''\n",
    "        Produce a list of the full image paths and class indices for all images\n",
    "        in the given set (found along the path).  Record a transform to be\n",
    "        applied by the __getitem__ method to each image.\n",
    "        '''\n",
    "        self.full_image_paths = []\n",
    "        self.class_names = class_names\n",
    "        self.gt_class_idx = []\n",
    "        for idx, nm in enumerate(class_names):\n",
    "            folder_path = os.path.join(path, nm)\n",
    "            image_paths = find_images_in_folder(folder_path, verbose)\n",
    "            self.full_image_paths += image_paths\n",
    "            self.gt_class_idx += [idx] * len(image_paths)\n",
    "\n",
    "        if new_size is not None:\n",
    "            self.transform = transforms.Compose([transforms.Resize(new_size),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=MEAN, std=STD)])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=MEAN, std=STD)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.full_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fp = self.full_image_paths[idx]\n",
    "        class_i = self.gt_class_idx[idx]\n",
    "        one_hot = np.zeros(5)\n",
    "        one_hot[class_i] = 1\n",
    "        one_hot_vector = torch.tensor(one_hot)\n",
    "        im = Image.open(fp)\n",
    "        im = self.transform(im)\n",
    "        return im, one_hot_vector\n",
    "        \n",
    "        \n",
    "class_names = ['grass', 'ocean', 'redcarpet', 'road', 'wheatfield']\n",
    "\n",
    "new_size = 240   # This reduces the original 240x360 images to 60x90.  Setting it to 240 leaves the images unchanged\n",
    "# new_size = None # Setting new_size to None keeps the original image size.\n",
    "verbose = False\n",
    "\n",
    "# Form all three datasets.\n",
    "train_dataset = HW4_Dataset(\"hw4_data/train\", class_names, new_size=new_size, verbose=verbose)\n",
    "valid_dataset = HW4_Dataset(\"hw4_data/valid\", class_names, new_size=new_size, verbose=verbose)\n",
    "test_dataset = HW4_Dataset(\"hw4_data/test\", class_names, new_size=new_size, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47d323f-1e8d-48a1-a3a0-d1152f1b1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Explore the constructed dataset\n",
    "'''\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find and output the number of images\n",
    "n = len(valid_dataset)\n",
    "# print(f'The validation dataset has {n} images')\n",
    "\n",
    "# Randomly shuffle the image indices\n",
    "indices = list(range(n))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Get the image and the class id of the 0th image after the shuffle.\n",
    "im, class_idx = valid_dataset[indices[0]]\n",
    "# print(f'After the shuffle the 0th image has class index {class_idx}')\n",
    "\n",
    "# Convert the image from an array back to a numpy 3d array\n",
    "im_np = im.numpy().transpose((1, 2, 0))\n",
    "# print(f'Image shape is {im_np.shape}')\n",
    "\n",
    "# Before displaying the image rescale the intensities to be between 0 and 1\n",
    "im_min = im_np.min()\n",
    "im_max = im_np.max()\n",
    "im_np = (im_np - im_min) / (im_max - im_min)\n",
    "\n",
    "# Display the image\n",
    "# plt.imshow(im_np)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "# print(class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96a7d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([32, 3, 240, 360])\n",
      "Shape of y: torch.Size([32, 5]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "#     print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "#     print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(f\"Using {device} device\")\n",
    "\n",
    "#conv nn from MNIST example\n",
    "from torch import nn\n",
    "class NeuralNetwork_Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork_Conv, self).__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            #modified input (feature depth) to match input tensors depth\n",
    "            #also doesn't change height/width\n",
    "            nn.Conv2d(3, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #halves height/width (now tensor is 120x180)\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #halves height/width, now 60x90\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            #singular fully connected, input is flattened img so 15x22 and output from convolutional\n",
    "            nn.Linear(60*90*32, 128),\n",
    "            nn.ReLU(),\n",
    "            #output layer matches num classes\n",
    "            nn.Linear(128, 5),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.fc_stack(self.conv_stack(x))\n",
    "        return logits\n",
    "\n",
    "# print()\n",
    "model = NeuralNetwork_Conv().to(device)\n",
    "# print(model)\n",
    "# for p in model.parameters():\n",
    "#     print(p.size())\n",
    "    \n",
    "# print()\n",
    "# mb = torch.rand(batch_size, 3, 240, 360).to(device)\n",
    "# logits = model.forward(mb)\n",
    "# print(logits.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f104f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "    training_loss /= len(dataloader)\n",
    "    return training_loss\n",
    "    \n",
    "        \n",
    "def validate(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    #so that we do not compute gradients, only model performance\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6f100c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training Loss: 1.6057454598672463\n",
      "Accuracy: 0.22533333333333333\n",
      "\n",
      "Epoch: 1\n",
      "Training Loss: 1.5927176989163412\n",
      "Accuracy: 0.27066666666666667\n",
      "\n",
      "Epoch: 2\n",
      "Training Loss: 1.5810231772674757\n",
      "Accuracy: 0.30266666666666664\n",
      "\n",
      "Epoch: 3\n",
      "Training Loss: 1.5690563654470626\n",
      "Accuracy: 0.32\n",
      "\n",
      "Epoch: 4\n",
      "Training Loss: 1.5557522725991226\n",
      "Accuracy: 0.344\n",
      "\n",
      "Epoch: 5\n",
      "Training Loss: 1.541804754700173\n",
      "Accuracy: 0.34933333333333333\n",
      "\n",
      "Epoch: 6\n",
      "Training Loss: 1.526509084947633\n",
      "Accuracy: 0.36133333333333334\n",
      "\n",
      "Epoch: 7\n",
      "Training Loss: 1.5096931998815502\n",
      "Accuracy: 0.39066666666666666\n",
      "\n",
      "Epoch: 8\n",
      "Training Loss: 1.4915984477283377\n",
      "Accuracy: 0.4053333333333333\n",
      "\n",
      "Epoch: 9\n",
      "Training Loss: 1.471558003426727\n",
      "Accuracy: 0.4093333333333333\n",
      "\n",
      "Epoch: 10\n",
      "Training Loss: 1.4497031015315742\n",
      "Accuracy: 0.41733333333333333\n",
      "\n",
      "Epoch: 11\n",
      "Training Loss: 1.4256636186192433\n",
      "Accuracy: 0.42533333333333334\n",
      "\n",
      "Epoch: 12\n",
      "Training Loss: 1.3996583958410405\n",
      "Accuracy: 0.428\n",
      "\n",
      "Epoch: 14\n",
      "Training Loss: 1.341870140625785\n",
      "Accuracy: 0.43466666666666665\n",
      "\n",
      "Epoch: 15\n",
      "Training Loss: 1.3113874527569296\n",
      "Accuracy: 0.43733333333333335\n",
      "\n",
      "Epoch: 16\n",
      "Training Loss: 1.2802839140958069\n",
      "Accuracy: 0.44\n",
      "\n",
      "Epoch: 17\n",
      "Training Loss: 1.2487458382394503\n",
      "Accuracy: 0.44533333333333336\n",
      "\n",
      "Epoch: 18\n",
      "Training Loss: 1.2186887163915812\n",
      "Accuracy: 0.448\n",
      "\n",
      "Epoch: 19\n",
      "Training Loss: 1.1893282425314695\n",
      "Accuracy: 0.452\n",
      "\n",
      "Epoch: 20\n",
      "Training Loss: 1.1607903204050452\n",
      "Accuracy: 0.4533333333333333\n",
      "\n",
      "Epoch: 21\n",
      "Training Loss: 1.1329534054194068\n",
      "Accuracy: 0.456\n",
      "\n",
      "Epoch: 23\n",
      "Training Loss: 1.0827469070681908\n",
      "Accuracy: 0.4573333333333333\n",
      "\n",
      "Epoch: 24\n",
      "Training Loss: 1.0608628739840986\n",
      "Accuracy: 0.45866666666666667\n",
      "\n",
      "Epoch: 25\n",
      "Training Loss: 1.0394776937290744\n",
      "Accuracy: 0.464\n",
      "\n",
      "Epoch: 26\n",
      "Training Loss: 1.0188524412613003\n",
      "Accuracy: 0.468\n",
      "\n",
      "Epoch: 27\n",
      "Training Loss: 0.9998185668548103\n",
      "Accuracy: 0.47333333333333333\n",
      "\n",
      "Epoch: 29\n",
      "Training Loss: 0.964292559788781\n",
      "Accuracy: 0.4786666666666667\n",
      "\n",
      "Epoch: 30\n",
      "Training Loss: 0.9479257053060627\n",
      "Accuracy: 0.48\n",
      "\n",
      "Epoch: 33\n",
      "Training Loss: 0.9028672235809305\n",
      "Accuracy: 0.484\n",
      "\n",
      "Epoch: 34\n",
      "Training Loss: 0.8892155048482174\n",
      "Accuracy: 0.48533333333333334\n",
      "\n",
      "Epoch: 37\n",
      "Training Loss: 0.8511404636514878\n",
      "Accuracy: 0.4866666666666667\n",
      "\n",
      "Epoch: 38\n",
      "Training Loss: 0.8395745906613725\n",
      "Accuracy: 0.488\n",
      "\n",
      "Epoch: 39\n",
      "Training Loss: 0.828410503940386\n",
      "Accuracy: 0.492\n",
      "\n",
      "Epoch: 40\n",
      "Training Loss: 0.8178103905953873\n",
      "Accuracy: 0.49466666666666664\n",
      "\n",
      "Epoch: 41\n",
      "Training Loss: 0.8073769331390256\n",
      "Accuracy: 0.49733333333333335\n",
      "\n",
      "Epoch: 42\n",
      "Training Loss: 0.797409968502038\n",
      "Accuracy: 0.49866666666666665\n",
      "\n",
      "Epoch: 43\n",
      "Training Loss: 0.7877692691714345\n",
      "Accuracy: 0.5\n",
      "\n",
      "Epoch: 45\n",
      "Training Loss: 0.769902886651934\n",
      "Accuracy: 0.5013333333333333\n",
      "\n",
      "Epoch: 46\n",
      "Training Loss: 0.7613900175457468\n",
      "Accuracy: 0.5026666666666667\n",
      "\n",
      "Epoch: 49\n",
      "Training Loss: 0.737780554506257\n",
      "Accuracy: 0.5053333333333333\n",
      "\n",
      "Epoch: 52\n",
      "Training Loss: 0.7166557219808029\n",
      "Accuracy: 0.5066666666666667\n",
      "\n",
      "Epoch: 60\n",
      "Training Loss: 0.6724595570585128\n",
      "Accuracy: 0.5093333333333333\n",
      "\n",
      "Epoch: 64\n",
      "Training Loss: 0.6557805781226168\n",
      "Accuracy: 0.5106666666666667\n",
      "\n",
      "Epoch: 73\n",
      "Training Loss: 0.6261500787878173\n",
      "Accuracy: 0.5146666666666667\n",
      "\n",
      "Epoch: 74\n",
      "Training Loss: 0.6233203672376999\n",
      "Accuracy: 0.516\n",
      "\n",
      "Epoch: 75\n",
      "Training Loss: 0.6205896544931695\n",
      "Accuracy: 0.52\n",
      "\n",
      "Epoch: 78\n",
      "Training Loss: 0.6130049133846307\n",
      "Accuracy: 0.5213333333333333\n",
      "\n",
      "Epoch: 83\n",
      "Training Loss: 0.6018311311786033\n",
      "Accuracy: 0.524\n",
      "\n",
      "Epoch: 86\n",
      "Training Loss: 0.595622519623226\n",
      "Accuracy: 0.528\n",
      "\n",
      "Epoch: 87\n",
      "Training Loss: 0.5935761480019948\n",
      "Accuracy: 0.5293333333333333\n",
      "\n",
      "Epoch: 88\n",
      "Training Loss: 0.5916012091129804\n",
      "Accuracy: 0.5333333333333333\n",
      "\n",
      "Epoch: 89\n",
      "Training Loss: 0.5897047713563959\n",
      "Accuracy: 0.536\n",
      "\n",
      "Epoch: 91\n",
      "Training Loss: 0.5858927423369695\n",
      "Accuracy: 0.5373333333333333\n",
      "\n",
      "Epoch: 94\n",
      "Training Loss: 0.5803009532255801\n",
      "Accuracy: 0.5386666666666666\n",
      "\n",
      "Epoch: 95\n",
      "Training Loss: 0.5784241799203665\n",
      "Accuracy: 0.54\n",
      "\n",
      "Epoch: 96\n",
      "Training Loss: 0.5765943845801151\n",
      "Accuracy: 0.544\n",
      "\n",
      "Epoch: 97\n",
      "Training Loss: 0.5748544155581543\n",
      "Accuracy: 0.5453333333333333\n",
      "\n",
      "Epoch: 100\n",
      "Training Loss: 0.5699800363238462\n",
      "Accuracy: 0.5466666666666666\n",
      "\n",
      "Epoch: 101\n",
      "Training Loss: 0.5682347768334377\n",
      "Accuracy: 0.548\n",
      "\n",
      "Epoch: 102\n",
      "Training Loss: 0.5665327375708936\n",
      "Accuracy: 0.5493333333333333\n",
      "\n",
      "Epoch: 103\n",
      "Training Loss: 0.5649195492387762\n",
      "Accuracy: 0.5533333333333333\n",
      "\n",
      "Epoch: 107\n",
      "Training Loss: 0.557657063668667\n",
      "Accuracy: 0.556\n",
      "\n",
      "Epoch: 108\n",
      "Training Loss: 0.5557295405319458\n",
      "Accuracy: 0.5573333333333333\n",
      "\n",
      "Epoch: 109\n",
      "Training Loss: 0.5538097412635942\n",
      "Accuracy: 0.5586666666666666\n",
      "\n",
      "Epoch: 111\n",
      "Training Loss: 0.550198597659019\n",
      "Accuracy: 0.56\n",
      "\n",
      "Epoch: 112\n",
      "Training Loss: 0.5485387569208108\n",
      "Accuracy: 0.5626666666666666\n",
      "\n",
      "Epoch: 113\n",
      "Training Loss: 0.5467345541057277\n",
      "Accuracy: 0.564\n",
      "\n",
      "Epoch: 115\n",
      "Training Loss: 0.5431405893546527\n",
      "Accuracy: 0.5666666666666667\n",
      "\n",
      "Epoch: 116\n",
      "Training Loss: 0.5412384093128999\n",
      "Accuracy: 0.568\n",
      "\n",
      "Epoch: 117\n",
      "Training Loss: 0.5394953589328967\n",
      "Accuracy: 0.5706666666666667\n",
      "\n",
      "Epoch: 118\n",
      "Training Loss: 0.5376174370255206\n",
      "Accuracy: 0.572\n",
      "\n",
      "Epoch: 119\n",
      "Training Loss: 0.5358231928573\n",
      "Accuracy: 0.5733333333333334\n",
      "\n",
      "Epoch: 120\n",
      "Training Loss: 0.5339085423527212\n",
      "Accuracy: 0.576\n",
      "\n",
      "Epoch: 121\n",
      "Training Loss: 0.5322014609170385\n",
      "Accuracy: 0.5773333333333334\n",
      "\n",
      "Epoch: 122\n",
      "Training Loss: 0.5303787128511251\n",
      "Accuracy: 0.58\n",
      "\n",
      "Epoch: 123\n",
      "Training Loss: 0.5285452432388084\n",
      "Accuracy: 0.5826666666666667\n",
      "\n",
      "Epoch: 124\n",
      "Training Loss: 0.5266029654038432\n",
      "Accuracy: 0.584\n",
      "\n",
      "Epoch: 126\n",
      "Training Loss: 0.5229378173805912\n",
      "Accuracy: 0.5866666666666667\n",
      "\n",
      "Epoch: 127\n",
      "Training Loss: 0.5209710586411764\n",
      "Accuracy: 0.5893333333333334\n",
      "\n",
      "Epoch: 128\n",
      "Training Loss: 0.5190896338596354\n",
      "Accuracy: 0.592\n",
      "\n",
      "Epoch: 129\n",
      "Training Loss: 0.5170998881113503\n",
      "Accuracy: 0.5946666666666667\n",
      "\n",
      "Epoch: 132\n",
      "Training Loss: 0.5115298470276152\n",
      "Accuracy: 0.5973333333333334\n",
      "\n",
      "Epoch: 133\n",
      "Training Loss: 0.5096806365392228\n",
      "Accuracy: 0.5986666666666667\n",
      "\n",
      "Epoch: 135\n",
      "Training Loss: 0.5059189816592301\n",
      "Accuracy: 0.6\n",
      "\n",
      "Epoch: 137\n",
      "Training Loss: 0.5021798278338531\n",
      "Accuracy: 0.6013333333333334\n",
      "\n",
      "Epoch: 141\n",
      "Training Loss: 0.4948621209934528\n",
      "Accuracy: 0.6026666666666667\n",
      "\n",
      "Epoch: 142\n",
      "Training Loss: 0.4929727372223383\n",
      "Accuracy: 0.604\n",
      "\n",
      "Epoch: 143\n",
      "Training Loss: 0.49113135401735747\n",
      "Accuracy: 0.6053333333333333\n",
      "\n",
      "Epoch: 144\n",
      "Training Loss: 0.4892615935918739\n",
      "Accuracy: 0.6066666666666667\n",
      "\n",
      "Epoch: 145\n",
      "Training Loss: 0.4874427245080268\n",
      "Accuracy: 0.608\n",
      "\n",
      "Epoch: 146\n",
      "Training Loss: 0.48553629949373356\n",
      "Accuracy: 0.6093333333333333\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "'''Learning Rate 1e-4, 3 conv (stride 1, padding 1) w/ 2 pools (2x2 kernel), 1 fully connected'''\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "epochs = 150\n",
    "best_accuracy = 0\n",
    "best_model = 'best_model.pth'\n",
    "for t in range(epochs):\n",
    "    training_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    validation_accuracy = validate(valid_dataloader, model, loss_fn)\n",
    "    if (validation_accuracy > best_accuracy):\n",
    "        best_accuracy = validation_accuracy\n",
    "        #save the model \n",
    "        torch.save(model, best_model)\n",
    "        print(\"Epoch:\", t)\n",
    "        print(\"Training Loss:\", training_loss)\n",
    "        print(\"Accuracy:\", best_accuracy)\n",
    "        print()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c6b09ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training Loss: 0.31635332958014883\n",
      "Accuracy: 0.2\n",
      "\n",
      "Epoch: 1\n",
      "Training Loss: 0.48589642325461213\n",
      "Accuracy: 0.20266666666666666\n",
      "\n",
      "Epoch: 20\n",
      "Training Loss: 0.3716062876936629\n",
      "Accuracy: 0.204\n",
      "\n",
      "Epoch: 28\n",
      "Training Loss: 0.26680702476068013\n",
      "Accuracy: 0.20533333333333334\n",
      "\n",
      "Epoch: 33\n",
      "Training Loss: 0.22037400237304494\n",
      "Accuracy: 0.21466666666666667\n",
      "\n",
      "Epoch: 38\n",
      "Training Loss: 0.1816286506332231\n",
      "Accuracy: 0.228\n",
      "\n",
      "Epoch: 42\n",
      "Training Loss: 0.1581944456221547\n",
      "Accuracy: 0.23733333333333334\n",
      "\n",
      "Epoch: 43\n",
      "Training Loss: 0.14258158562706819\n",
      "Accuracy: 0.24266666666666667\n",
      "\n",
      "Epoch: 49\n",
      "Training Loss: 0.09976205417901468\n",
      "Accuracy: 0.248\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "'''Learning Rate 1e-2, 3 conv (stride 1, padding 1) w/ 2 pools (2x2 kernel), 1 fully connected'''\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "epochs = 50\n",
    "best_accuracy = 0\n",
    "#best_model = 'best_model.pth'\n",
    "for t in range(epochs):\n",
    "    training_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    validation_accuracy = validate(valid_dataloader, model, loss_fn)\n",
    "    if (validation_accuracy > best_accuracy):\n",
    "        best_accuracy = validation_accuracy\n",
    "        #torch.save(model, best_model)\n",
    "        print(\"Epoch:\", t)\n",
    "        print(\"Training Loss:\", training_loss)\n",
    "        print(\"Accuracy:\", best_accuracy)\n",
    "        print()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4cf80500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training Loss: 1.6130496804122674\n",
      "Accuracy: 0.18666666666666668\n",
      "\n",
      "Epoch: 4\n",
      "Training Loss: 1.6122589665380391\n",
      "Accuracy: 0.188\n",
      "\n",
      "Epoch: 5\n",
      "Training Loss: 1.6120633262124928\n",
      "Accuracy: 0.18933333333333333\n",
      "\n",
      "Epoch: 6\n",
      "Training Loss: 1.6118676887430026\n",
      "Accuracy: 0.19066666666666668\n",
      "\n",
      "Epoch: 8\n",
      "Training Loss: 1.6114773856532392\n",
      "Accuracy: 0.192\n",
      "\n",
      "Epoch: 10\n",
      "Training Loss: 1.611088868287025\n",
      "Accuracy: 0.19333333333333333\n",
      "\n",
      "Epoch: 11\n",
      "Training Loss: 1.610895669347409\n",
      "Accuracy: 0.19466666666666665\n",
      "\n",
      "Epoch: 13\n",
      "Training Loss: 1.6105091728044278\n",
      "Accuracy: 0.196\n",
      "\n",
      "Epoch: 14\n",
      "Training Loss: 1.6103161138228395\n",
      "Accuracy: 0.19866666666666666\n",
      "\n",
      "Epoch: 15\n",
      "Training Loss: 1.6101230914281173\n",
      "Accuracy: 0.2\n",
      "\n",
      "Epoch: 16\n",
      "Training Loss: 1.6099300114155717\n",
      "Accuracy: 0.20133333333333334\n",
      "\n",
      "Epoch: 17\n",
      "Training Loss: 1.609737072252866\n",
      "Accuracy: 0.20266666666666666\n",
      "\n",
      "Epoch: 20\n",
      "Training Loss: 1.6091577035459605\n",
      "Accuracy: 0.20533333333333334\n",
      "\n",
      "Epoch: 49\n",
      "Training Loss: 1.6036491732028397\n",
      "Accuracy: 0.20666666666666667\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "'''Learning Rate 1e-6, 3 conv (stride 1, padding 1) w/ 2 pools (2x2 kernel), 1 fully connected'''\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "epochs = 50\n",
    "best_accuracy = 0\n",
    "#best_model = 'best_model.pth'\n",
    "for t in range(epochs):\n",
    "    training_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    validation_accuracy = validate(valid_dataloader, model, loss_fn)\n",
    "    if (validation_accuracy > best_accuracy):\n",
    "        best_accuracy = validation_accuracy\n",
    "        #torch.save(model, best_model)\n",
    "        print(\"Epoch:\", t)\n",
    "        print(\"Training Loss:\", training_loss)\n",
    "        print(\"Accuracy:\", best_accuracy)\n",
    "        print()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ad1d95a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Neural Network with more conv layers, max pooling, and fully connected layers'''\n",
    "class NeuralNetwork_MoreConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork_MoreConv, self).__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            #modified input (feature depth) to match input tensors depth\n",
    "            #also doesn't change height/width\n",
    "            nn.Conv2d(3, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #halves height/width, now tensor is 120x180\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #60x90\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #30x45\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #15x22\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            #singular fully connected, input is flattened img so 15x22 and output from convolutional\n",
    "            nn.Linear(15*22*128, 256),\n",
    "            nn.ReLU(),\n",
    "            #another fully connected layer\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            #another fully connected layer\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            #output layer, matches num classes\n",
    "            nn.Linear(64, 5),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.fc_stack(self.conv_stack(x))\n",
    "        return logits\n",
    "    \n",
    "model_conv = NeuralNetwork_MoreConv().to(device)\n",
    "# print(model_conv)\n",
    "# for p in model_conv.parameters():\n",
    "#     print(p.size())\n",
    "    \n",
    "# print()\n",
    "# mb = torch.rand(batch_size, 3, 240, 360).to(device)\n",
    "# logits = model_conv.forward(mb)\n",
    "# print(logits.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "413bfb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training Loss: 1.6097832491564932\n",
      "Accuracy: 0.2\n",
      "\n",
      "Epoch: 31\n",
      "Training Loss: 1.6094334858949437\n",
      "Accuracy: 0.20266666666666666\n",
      "\n",
      "Epoch: 36\n",
      "Training Loss: 1.6093823815385502\n",
      "Accuracy: 0.204\n",
      "\n",
      "Epoch: 38\n",
      "Training Loss: 1.6093620294535702\n",
      "Accuracy: 0.20666666666666667\n",
      "\n",
      "Epoch: 40\n",
      "Training Loss: 1.6093417504971677\n",
      "Accuracy: 0.20933333333333334\n",
      "\n",
      "Epoch: 43\n",
      "Training Loss: 1.6093106651057798\n",
      "Accuracy: 0.21066666666666667\n",
      "\n",
      "Epoch: 46\n",
      "Training Loss: 1.6092791597499991\n",
      "Accuracy: 0.212\n",
      "\n",
      "Epoch: 47\n",
      "Training Loss: 1.6092686906231173\n",
      "Accuracy: 0.21333333333333335\n",
      "\n",
      "Epoch: 49\n",
      "Training Loss: 1.609248060405706\n",
      "Accuracy: 0.21466666666666667\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "'''Learning Rate 1e-4, 5 conv (stride 1, padding 1) w/ 4 pools (2x2 kernel), 3 fully connected'''\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "epochs = 50\n",
    "best_accuracy = 0\n",
    "best_model_conv = 'best_model_conv.pth'\n",
    "for t in range(epochs):\n",
    "    training_loss = train(train_dataloader, model_conv, loss_fn, optimizer)\n",
    "    validation_accuracy = validate(valid_dataloader, model_conv, loss_fn)\n",
    "    if (validation_accuracy > best_accuracy):\n",
    "        best_accuracy = validation_accuracy\n",
    "        #save the model \n",
    "        torch.save(model_conv, best_model)\n",
    "        print(\"Epoch:\", t)\n",
    "        print(\"Training Loss:\", training_loss)\n",
    "        print(\"Accuracy:\", best_accuracy)\n",
    "        print()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "21f2d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Taken from part 1'''\n",
    "def compute_accuracy(test_pairs, num_classes):\n",
    "    test_pairs_np = np.array(test_pairs)\n",
    "    correct = np.sum(test_pairs_np[:, 0] == test_pairs_np[:, 1])\n",
    "    return correct / len(test_pairs)\n",
    "\n",
    "def compute_per_class_accuracy(test_pairs, num_classes):\n",
    "    test_pairs_np = np.array(test_pairs)\n",
    "    true_labels = test_pairs_np[:, 0]\n",
    "    predicted = test_pairs_np[:, 1]\n",
    "    classes = np.bincount(true_labels)\n",
    "    correct = np.bincount(true_labels[true_labels == predicted])\n",
    "    \n",
    "    return correct/classes\n",
    "\n",
    "def compute_confusion_matrix(test_pairs, num_classes):\n",
    "    test_pairs_np = np.array(test_pairs)\n",
    "    confusion = np.bincount(test_pairs_np[:, 0] * num_classes + test_pairs_np[:, 1]).reshape(num_classes, num_classes)\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b8c343ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "            \n",
    "            predicted_labels.extend(pred.argmax(1).cpu())\n",
    "            true_labels.extend(y.argmax(1).cpu())\n",
    "\n",
    "    correct /= size\n",
    "    return predicted_labels, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "63e6b9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.57\n",
      "\n",
      "Per class accuracy\n",
      "0: 0.96\n",
      "1: 0.70\n",
      "2: 0.98\n",
      "3: 0.66\n",
      "4: 0.38\n",
      "\n",
      "Confusion matrix\n",
      " 0: 25  0  0  0  1\n",
      " 1: 29 85  0  4  4\n",
      " 2:  1  0 87  1  0\n",
      " 3: 23 19  3 92  3\n",
      " 4: 72 46 60 53 142\n"
     ]
    }
   ],
   "source": [
    "'''Final Test using best weights from original parameters (learning rate 1e-4, 3 conv, 2 pool, 1 layer)'''\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "final_model = torch.load(best_model)\n",
    "final_model.eval()\n",
    "pred, true = test(test_dataloader, final_model, loss_fn)\n",
    "pairs = np.column_stack((pred, true)).astype(int)\n",
    "\n",
    "accuracy = compute_accuracy(pairs, len(class_names))\n",
    "print(f'Overall Accuracy: {accuracy:.2f}')\n",
    "\n",
    "per_class_accuracy = compute_per_class_accuracy(pairs, len(class_names))\n",
    "print()\n",
    "print('Per class accuracy')\n",
    "for i, acc in enumerate(per_class_accuracy):\n",
    "    print(f'{i}: {acc:4.2f}')\n",
    "    \n",
    "cm = compute_confusion_matrix(pairs, len(class_names))\n",
    "print(f'\\nConfusion matrix')\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{i:2d}:', end='')\n",
    "    for j in range(len(class_names)):\n",
    "        print(f' {cm[i, j]:2d}', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edc535",
   "metadata": {},
   "source": [
    "Discussion: \n",
    "\n",
    "My experimental results are a bit lacking considering that I utilized only 50 epochs to check for the best parameters and weights. I realize that a smaller learning rate might take longer to converge and 50 epochs is too small to realize that convergence. However, a greater learning rate (1e-2) began to pick up much slower compared to 1e-4, which surprised me. As for design choices, I played with the number of convolutional layers and fully connected layers using the learning rate that outperformed the others within 50 epochs. Again, because I had limited the epochs to 50, the full potential of the network may not have been brought out since the accuracy was stuck at 0.2 and didn't have a chance to pick up. All experiments had the same loss function and optimizer function. In the end, the first set of parameters I experimented with outshined the rest within the 50 epochs so I chose those parameters to train using 150 epochs.\n",
    "\n",
    "The classifier works well in classifying red carpets especially, which makes sense considering its distinctiveness. I would consider the ocean to be the 2nd most easily classifiable. This is mainly because the classifier was unable to correctly guess the grass backgrounds in previous best models for the final test. Still, the number of grass images are substantially lower than the others. As just mentioned, the classifier works poorly with grass backgrounds as well as wheat fields. This makes sense because of their similar features. We can see a higher incorrect predictions of grasslands for the wheatfields compared to other backgrounds and the singular incorrect prediction of a wheatfield for the grasslands.\n",
    "\n",
    "If I had more time, I would definitely have run 200 epochs per experiment to figure out the best parameters, but the amount of time training these neural networks took much longer than expected on my local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef0039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
